{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, you'll use the modeling module to train and register models\n",
    "\n",
    "\n",
    "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142055606
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142060995
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142061399
    }
   },
   "outputs": [],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142061563
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Verify that the handle works correctly.\n",
    "# If you ge an error here, modify your SUBSCRIPTION, RESOURCE_GROUP, and WS_NAME in the previous cell.\n",
    "ws = ml_client.workspaces.get(\"ml-sandbox-core\")\n",
    "print(ws.location, \":\", ws.resource_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Data Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142061850
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root_directory = os.getcwd().split(\"/notebooks\")[0]\n",
    "sys.path.insert(0, project_root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070073
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from core.modeling.config import ModelingConfig, MethodConfig\n",
    "from core.modeling.pipeline import ModelingPipelineBuilder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070173
    }
   },
   "outputs": [],
   "source": [
    "# Create the MLPipelineConfig object\n",
    "config = ModelingConfig(\n",
    "    model_name=\"Linear Regression\",\n",
    "    data_preprocessing_steps=[\n",
    "        MethodConfig(name=\"sklearn.preprocessing.Normalizer\", params=dict(norm=\"l2\")),\n",
    "    ],\n",
    "    model_estimator=MethodConfig(\n",
    "        name=\"sklearn.linear_model.Ridge\", params=dict(alpha=0.9)\n",
    "    ),\n",
    "    track_experiment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070309
    }
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Simple Usage with Diabetes Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070430
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_diabetes(as_frame=True)\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070585
    }
   },
   "outputs": [],
   "source": [
    "pipeline_builder = ModelingPipelineBuilder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070710
    }
   },
   "outputs": [],
   "source": [
    "pipeline_builder.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070818
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = pipeline_builder.split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142070964
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pipeline_builder.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142071074
    }
   },
   "outputs": [],
   "source": [
    "pipeline_builder.fit()\n",
    "\n",
    "test_score = pipeline_builder.pipeline.score(X_test, y_test)\n",
    "train_score = pipeline_builder.pipeline.score(X_train, y_train)\n",
    "print(f\"Test Score: {test_score}\")\n",
    "print(f\"Train Score: {train_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Checking for existing de env\n",
    "\n",
    "Let's explore the environments within the workspace.\n",
    "\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142071223
    }
   },
   "outputs": [],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the job with the new custom environment triggers the build of the environment. The first time you use a newly created environment, it can take 10-15 minutes to build the environment, which also means your job will take longer to complete.\n",
    "You can also choose to manually trigger the build of the environment before you submit a job. The environment only needs to be built the first time you use it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Creating a job to use a data asset\n",
    "\n",
    "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
    "\n",
    "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. Also, it is possible to read these data directly from the job.\n",
    "\n",
    "The cells below creates the **main.py** script in the **src** folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../main.py\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "current_path = os.path.dirname(os.path.abspath(__file__))\n",
    "import mltable\n",
    "\n",
    "\n",
    "from core.modeling.config import ModelingConfig, MethodConfig\n",
    "from core.modeling.pipeline import ModelingPipelineBuilder\n",
    "import pandas as pd\n",
    "\n",
    "# Create the MLPipelineConfig object\n",
    "config = ModelingConfig(\n",
    "    model_name=\"Linear Regression\",\n",
    "    data_preprocessing_steps=[\n",
    "        MethodConfig(\n",
    "            name=\"sklearn.preprocessing.Normalizer\", params=dict(norm=\"l2\")\n",
    "        ),\n",
    "    ],\n",
    "    model_estimator=MethodConfig(\n",
    "        name=\"sklearn.linear_model.Ridge\", params=dict(alpha=0.9)\n",
    "    ),\n",
    "    track_experiment=True\n",
    ")\n",
    "\n",
    "\n",
    "tbl = mltable.load(f\"azureml://...path...\")\n",
    "df = tbl.to_pandas_dataframe()\n",
    "X = df.drop([\"Price\"], axis = 1)\n",
    "y = pd.DataFrame(df[\"Price\"].copy())\n",
    "\n",
    "pipeline_builder = ModelingPipelineBuilder(config)\n",
    "pipeline_builder.split_data(X, y)\n",
    "\n",
    "pipeline_builder.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To submit a job that runs the **main.py** script, run the cell below. \n",
    "\n",
    "The job is configured to use the data asset `diabetes-local`, pointing to the local **mobile-price-local.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_mobileprice_cleaned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142240360
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"../\",\n",
    "    command=\"python main.py\",\n",
    "    environment=\"docker-context-repo-based-v1:1\",\n",
    "    compute=\"sandbox-ci\",\n",
    "    display_name=\"training-mobile-data\",  # if we dont define it, it will be the run name definition\n",
    "    experiment_name=\"mobile-price-exp\",\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor the job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a component to execute a pipeline  (using yaml definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%%writefile example_configs/config.yml\n",
    "# <component>\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "name: train_credit_defaults_model\n",
    "display_name: training-mobile-data\n",
    "description: Training job for mobile price data\n",
    "# version: 1 # Not specifying a version will automatically update the version\n",
    "code: .\n",
    "environment: azureml:docker-context-repo-based-v1:1\n",
    "command: >-\n",
    "  python main.py \n",
    "# </component>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Optionally, register the component in the workspace for future reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709058
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing the Component Package\n",
    "from azure.ai.ml import load_component\n",
    "\n",
    "# Loading the component from the yml file\n",
    "train_component = load_component(source=os.path.join(\"../\", \"config.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709065
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {train_component.name} and {train_component.command} with Version {train_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709071
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# the dsl decorator tells the sdk that we are defining an Azure ML pipeline\n",
    "from azure.ai.ml import dsl, Input, Output\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=\"sandbox-demo-ci\",\n",
    "    description=\"training pipeline\",\n",
    ")\n",
    "def mobile_defaults_pipeline():\n",
    "\n",
    "    # using train_func like a python call with its own inputs\n",
    "    train_job = train_component()\n",
    "\n",
    "    # a pipeline returns a dictionary of outputs\n",
    "    # keys will code for the pipeline output identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709078
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Let's instantiate the pipeline with the parameters of our choice\n",
    "pipeline = mobile_defaults_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709083
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline,\n",
    "    experiment_name=\"mobile-price-exp\",\n",
    "    # Project's name\n",
    ")\n",
    "# open the pipeline in web browser\n",
    "webbrowser.open(pipeline_job.studio_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Registering models by run (after job execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142626014
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from core.modeling.deployment import DeploymentPipeline\n",
    "from core.modeling.config import DeploymentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142627096
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "config = DeploymentConfig(model_name=\"mobile-price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142629056
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "obj = DeploymentPipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142647512
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "_, exp_names = obj.get_all_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142654497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "exp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142661098
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = exp_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723142664420
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "obj.register_model(experiment_id=experiment_id, metric=\"test_mse\", metric_mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722955138843
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "\n",
    "def get_all_runs_by_experiment(experiment_name):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "    if experiment is None:\n",
    "        raise ValueError(f\"Experiment with name {experiment_name} does not exist.\")\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment.experiment_id], run_view_type=ViewType.ALL\n",
    "    )\n",
    "\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722955420165
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "get_all_runs_by_experiment(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722954709158
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "mlflow.delete_experiment(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "condav0"
  },
  "kernelspec": {
   "display_name": "condav0",
   "language": "python",
   "name": "condav0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
