{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the pipeline resources\n",
    "\n",
    "The Azure ML framework can be used from CLI, Python SDK, or studio interface. In this example, you'll use the AzureML Python SDK v2 to create a pipeline. \n",
    "\n",
    "Before creating the pipeline, you'll set up the resources the pipeline will use:\n",
    "\n",
    "* The dataset for training\n",
    "* The software environment to run the pipeline\n",
    "\n",
    "## Connect to the workspace\n",
    "\n",
    "Before we dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it does not work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723143206271
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "Python"
     ],
     "id": ""
    },
    "gather": {
     "logged": 1723143208810
    },
    "name": "import-mlclient"
   },
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find your Subscription ID:\n",
    "1. In the upper right Azure Machine Learning Studio toolbar, select your workspace name.\n",
    "1. At the bottom, select **View all properties in Azure Portal**\n",
    "1. Copy the value from Azure Portal into the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "Python"
     ],
     "id": ""
    },
    "gather": {
     "logged": 1723143209162
    },
    "name": "ml_client"
   },
   "outputs": [],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a handler to the workspace that you'll use to manage other resources and jobs.\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (in the notebook below, that will happen during dataset registration).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as batch endpoint\n",
    "\n",
    "Now deploy your machine learning model as a web service in the Azure cloud, an [`batch endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
    "\n",
    "To deploy a machine learning service, you usually need:\n",
    "\n",
    "* The entry script must understand the data that the model expects and returns. When using a MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new batch endpoint\n",
    "\n",
    "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "Python"
     ],
     "id": ""
    },
    "gather": {
     "logged": 1723143210460
    },
    "name": "online_endpoint_name"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "endpoint_name = \"batch-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722962281890
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchEndpoint\n",
    "\n",
    "# create a batch endpoint\n",
    "endpoint = BatchEndpoint(\n",
    "    name=endpoint_name,\n",
    "    description=\"A batch endpoint for predicting mobile prices\",\n",
    ")\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722962431881
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root_directory = os.getcwd().split(\"/notebooks\")[0]\n",
    "sys.path.insert(0, project_root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722962435729
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from core.modeling.deployment import DeploymentPipeline\n",
    "from core.modeling.config import DeploymentConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723149542567
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model = DeploymentPipeline(DeploymentConfig).load_registered_model(\n",
    "    model_name=\"mobile-price\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "for more details about the configuration\n",
    "\n",
    "https://learn.microsoft.com/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.batchdeployment?view=azure-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "Python"
     ],
     "id": ""
    },
    "gather": {
     "logged": 1723143582682
    },
    "name": "endpoint"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\n",
    "from azure.ai.ml.constants import BatchDeploymentOutputAction\n",
    "\n",
    "deployment = BatchDeployment(\n",
    "    name=name\n",
    "    description=\"regressor-mobile-mlflow\",\n",
    "    endpoint_name=endpoint.name,\n",
    "    model=model.id,\n",
    "    compute=\"sandbox-ci\",\n",
    "    settings=ModelBatchDeploymentSettings(\n",
    "        max_concurrency_per_instance=2,\n",
    "        mini_batch_size=10,\n",
    "        instance_count=2,\n",
    "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
    "        output_file_name=\"predictions.csv\",\n",
    "        retry_settings=BatchRetrySettings(max_retries=3, timeout=30),\n",
    "        logging_level=\"info\",\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722964040838
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.batch_deployments.begin_create_or_update(deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Now that you have deployed a model to a batch endpoint, and have an unlabeled data asset, you're ready to invoke the endpoint to generate predictions on the unlabeled data.\n",
    "\n",
    "First, you'll define the input by referring to the registered data asset. Then, you'll invoke the endpoint, which will submit a pipeline job. You can use the job URL to monitor it in the Studio. The job will contain a child job that represents the running of the (generated) scoring script to get the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722965236189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "deployment.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722965241881
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "endpoint.defaults = {}\n",
    "\n",
    "endpoint.defaults[\"deployment_name\"] = deployment.name\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "endpoint.defaults = {}\n",
    "\n",
    "endpoint.defaults[\"deployment_name\"] = deployment.name\n",
    "\n",
    "ml_client.batch_endpoints.begin_create_or_update(endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with a sample query\n",
    "\n",
    "Now that the model is deployed to the endpoint, you can run inference with it.\n",
    "\n",
    "Create a sample request file following the design expected in the run method in the score script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722966140737
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml.entities import Data\n",
    "\n",
    "data_path = \"../data/sample.csv\"\n",
    "dataset_name = \"mobile-price-sample-endpoint\"\n",
    "\n",
    "mobile_price_sample = Data(\n",
    "    path=data_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Sample to test the endpoint.\",\n",
    "    name=dataset_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722966142930
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.data.create_or_update(mobile_price_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722966469769
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722966461698
    },
    "name": "write-sample-request"
   },
   "outputs": [],
   "source": [
    "mobile_price_sample = ml_client.data.get(name=dataset_name, label=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Get logs of the deployment\n",
    "\n",
    "Check the logs to see whether the endpoint/deployment were invoked successfully. If you face errors, see Troubleshooting online endpoints deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1722966441868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "\n",
    "input = Input(path=mobile_price_sample.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "Python"
     ],
     "id": ""
    },
    "gather": {
     "logged": 1722966785437
    },
    "name": "ml_client.online_endpoints.invoke"
   },
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "job = ml_client.batch_endpoints.invoke(\n",
    "    endpoint_name=endpoint_name,\n",
    "    input=input,\n",
    "    deployment_name=deployment.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ml_client.jobs.get(job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "logs = ml_client.online_deployments.get_logs(\n",
    "    name=\"blue\", endpoint_name=online_endpoint_name, lines=50\n",
    ")\n",
    "print(logs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "\n",
    "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
    "\n",
    "\n",
    "> [!NOTE]\n",
    "> Expect this step to take approximately 6 to 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "python "
     ],
     "id": ""
    },
    "name": "ml_client.online_endpoints.begin_delete"
   },
   "outputs": [],
   "source": [
    "ml_client.batch_endpoints.begin_delete(name=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "description": {
   "description": "Create production ML pipelines with Python SDK v2 in a Jupyter notebook"
  },
  "kernel_info": {
   "name": "condav0"
  },
  "kernelspec": {
   "display_name": "condav0",
   "language": "python",
   "name": "condav0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
