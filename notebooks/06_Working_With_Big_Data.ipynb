{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, you'll explore how to get data from datastores (big data) and using data assets.\n",
    "\n",
    "\n",
    "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This is important if you want to use your `.py` modules to create jobs, rather than writing your code directly in the notebook.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1740662360313
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root_directory = os.getcwd().split(\"/notebooks\")[0]\n",
    "sys.path.insert(0, project_root_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1740662396573
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1740662402732
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Configure de env\n",
    "\n",
    "Let's explore the environments within the workspace.\n",
    "\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultNcdEnv-openmpi4-1-0-cuda11-8-cudnn8-ubuntu22-04\n",
      "realesr_inference\n",
      "fine-tunning-embedding\n",
      "batch-inference-ncd-env\n",
      "DefaultNcdEnv-ai-ml-automl\n",
      "inferencing-env\n",
      "custom-env-embedding\n",
      "DefaultNcdEnv-foundation-model-inference\n",
      "env-fine-tuning-inference\n",
      "env-fine-tuning\n",
      "fine-tuning-v3\n",
      "fine-tuning-conda\n",
      "finetuning-env\n",
      "fine-tuning-env-2\n",
      "fine-tuning-env\n",
      "DefaultNcdEnv-mlflow-ubuntu20-04-py38-cpu-inference\n",
      "docker-context-repo-based-v1\n",
      "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the job with the new custom environment triggers the build of the environment. The first time you use a newly created environment, it can take 10-15 minutes to build the environment, which also means your job will take longer to complete.\n",
    "You can also choose to manually trigger the build of the environment before you submit a job. The environment only needs to be built the first time you use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the container and data store if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "\n",
    "account_url = f\"https://{os.getenv(\"storage_account_name\")}.blob.core.windows.net\"\n",
    "\n",
    "# Create the BlobServiceClient object\n",
    "blob_service_client = BlobServiceClient(account_url, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blob_container(blob_service_client: BlobServiceClient, container_name):\n",
    "    try:\n",
    "        container_client = blob_service_client.create_container(name=container_name)\n",
    "    except ResourceExistsError:\n",
    "        print(\"A container with this name already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AzureCliCredential.get_token_info failed: Please run 'az login' to set up an account\n"
     ]
    }
   ],
   "source": [
    "create_blob_container(blob_service_client, \"mobile-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob_file(self, blob_service_client: BlobServiceClient, container_name: str):\n",
    "    container_client = blob_service_client.get_container_client(\n",
    "        container=container_name\n",
    "    )\n",
    "    with open(file=os.path.join(\"filepath\", \"filename\"), mode=\"rb\") as data:\n",
    "        blob_client = container_client.upload_blob(\n",
    "            name=\"sample-blob.txt\", data=data, overwrite=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_blob_container(blob_service_client, \"mobile-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore 'my_datalake' created successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import AzureDataLakeGen2Datastore\n",
    "\n",
    "# Replace with your Data Lake account details\n",
    "account_name = os.getenv(\"storage_account_name\")\n",
    "filesystem_name = \"mobile-price\"\n",
    "\n",
    "datalake_datastore = AzureDataLakeGen2Datastore(\n",
    "    name=\"my_datalake\",\n",
    "    account_name=account_name,\n",
    "    filesystem=filesystem_name,\n",
    ")\n",
    "\n",
    "created_datastore = ml_client.datastores.create_or_update(datalake_datastore)\n",
    "print(f\"Datastore '{created_datastore.name}' created successfully!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## List the datastores\n",
    "\n",
    "When you create the Azure Machine Learning workspace, an Azure Storage Account is created too. The Storage Account includes Blob and file storage and are automatically connected with your workspace as **datastores**. You can list all datastores connected to your workspace:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### List the datastores.\n",
    "\n",
    "We can also use https://learn.microsoft.com/en-us/azure/machine-learning/how-to-access-data-interactive?view=azureml-api-2&tabs=adls\n",
    "\n",
    "to access data during interactive development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1726753989524
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_datalake\n",
      "azureml\n",
      "azureml_globaldatasets\n",
      "blob_mobileprice_cleaned\n",
      "workspaceworkingdirectory\n",
      "workspacefilestore\n",
      "workspaceblobstore\n",
      "workspaceartifactstore\n"
     ]
    }
   ],
   "source": [
    "stores = ml_client.datastores.list()\n",
    "for ds_name in stores:\n",
    "    print(ds_name.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### We are going to read data directly from Data Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1740662533283
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Azure Machine Learning workspace details:\n",
    "subscription = os.getenv(\"subscription\")\n",
    "resource_group = os.getenv(\"subscription\")\n",
    "workspace = os.getenv(\"workspace\")\n",
    "datastore_name = os.getenv(\"datastore_name\")\n",
    "path_on_datastore = os.getenv(\"path_on_datastore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create data assets using local folder\n",
    "\n",
    "To point to a specific folder or file in a datastore, you can create data assets. There are three types of data assets:\n",
    "\n",
    "- `URI_FILE` points to a specific file.\n",
    "- `URI_FOLDER` points to a specific folder.\n",
    "- `MLTABLE` points to a MLTable file which specifies how to read one or more files within a folder.\n",
    "\n",
    "You'll create all three types of data assets to experience the differences between them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To create a `URI_FILE` data asset, you have to specify a path that points to a specific file. The path can be a local path or cloud path.\n",
    "\n",
    "In the example below, you'll create a data asset by referencing a *local* path. To ensure the data is always available when working with the Azure Machine Learning workspace, local files will automatically be uploaded to the default datastore. In this case, the `diabetes.csv` file will be uploaded to **LocalUpload** folder in the **workspaceblobstore** datastore. \n",
    "\n",
    "To create a data asset from a local file, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723124273022
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = \"../data/Mobile-Price-Prediction-cleaned_data.csv\"\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
    "    name=\"mobile-price-local\",\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
    "\n",
    "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723124785753
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_path = \"../data\"\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
    "    name=\"mobile-price-table\",\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1723124788110
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "datasets = ml_client.data.list()\n",
    "for ds_name in datasets:\n",
    "    print(ds_name.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data asset using DataLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1740663284261
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset registered successfully!\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "data_uri = f\"azureml://datastores/{datastore_name}/paths/{path_on_datastore}/Mobile-Price-Prediction-cleaned_data.csv\"\n",
    "\n",
    "datalake_data_asset = Data(\n",
    "    name=\"datalake-price-data\",\n",
    "    path=data_uri,\n",
    "    type=AssetTypes.URI_FILE,\n",
    "    description=\"Data asset pointing to a file in Azure Data Lake via the datastore\",\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(datalake_data_asset)\n",
    "print(\"Data asset registered successfully!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Read data in notebook\n",
    "\n",
    "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
    "\n",
    "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
    "\n",
    "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "gather": {
     "logged": 1740663411362
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>RAM</th>\n",
       "      <th>ROM</th>\n",
       "      <th>Mobile_Size</th>\n",
       "      <th>Primary_Cam</th>\n",
       "      <th>Selfi_Cam</th>\n",
       "      <th>Battery_Power</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>48</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>24999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>48</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>15999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>48</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3800</td>\n",
       "      <td>18999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>35</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3800</td>\n",
       "      <td>18999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>3.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>48</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>4.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>1390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3800</td>\n",
       "      <td>9790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>3.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3500</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ratings   RAM    ROM  Mobile_Size  Primary_Cam  Selfi_Cam  Battery_Power  \\\n",
       "0        4.3   4.0  128.0         6.00           48       13.0           4000   \n",
       "1        3.4   6.0   64.0         4.50           48       12.0           4000   \n",
       "2        4.3   4.0    4.0         4.50           64       16.0           4000   \n",
       "3        4.4   6.0   64.0         6.40           48       15.0           3800   \n",
       "4        4.5   6.0  128.0         6.18           35       15.0           3800   \n",
       "..       ...   ...    ...          ...          ...        ...            ...   \n",
       "802      3.8   6.0   32.0         4.54           48       12.0           2800   \n",
       "803      4.1   8.0   64.0         4.54           64        8.0           2500   \n",
       "804      4.4   3.0   32.0         6.20           48        1.0           3800   \n",
       "805      3.7  10.0   32.0         4.50           64        8.0           3500   \n",
       "806      3.5   6.0   32.0         4.50           64       15.0           1050   \n",
       "\n",
       "     Price  \n",
       "0    24999  \n",
       "1    15999  \n",
       "2    15000  \n",
       "3    18999  \n",
       "4    18999  \n",
       "..     ...  \n",
       "802   1299  \n",
       "803   1390  \n",
       "804   9790  \n",
       "805    799  \n",
       "806    799  \n",
       "\n",
       "[807 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
    "data_asset = ml_client.data.get(\"datalake-price-data\", version=\"3\")\n",
    "\n",
    "df = pd.read_csv(data_asset.path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
